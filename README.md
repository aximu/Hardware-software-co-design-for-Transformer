# Hardware-software co-design for Transformer(Attention based NNs)
Interesting open source design, system architecture, hardware and algorithm co-design 

1. [TransCODE: Co-design of Transformers and Accelerators for Efficient Training and Inference](https://github.com/JHA-Lab/transcode)
2. [Butterfly Accelerator for Efficient Transformer](https://github.com/SamsungLabs/Butterfly_Acc)
3. [BERT Model on Silicon](https://github.com/alimpk/bert-on-silicon)
4. [transformer-cpp-cpu](https://github.com/dianhsu/transformer-cpp-cpu)
5. [NiuTrans.NMT](https://github.com/NiuTrans/NiuTrans.NMT)
6. [HLS_Transformer](https://github.com/zhengchen3/HLS_Transformer)
7. [transformer_core](https://github.com/qyw123/transformer_core)

